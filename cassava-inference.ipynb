{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Directory settings"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = './'\nMODEL_DIR = '../input/cassava-resnext50-32x4d-weights-test/'\nMODEL_DIR_TEST = '../input/cassava-weights-test/'\nMODEL_DIR_RES = '../input/cassava-resnext50-32x4d-weights/'\nMODEL_DIR_SERES_MIX = '../input/cassava-seresnext50-32x4d-weights/'\nMODEL_DIR_SERES_NO = '../input/cassava-seresnext50-32x4d-weights-nomix/'\nMODEL_DIR_EFNET4 = '../input/cassava-efficientnet-b4-weights/'\nMODEL_DIR_EFNET5 = '../input/cassava-efficientnet-b5-weights/'\nMODEL_DIR_CSP = '../input/cassava-cspresnext50-weights/'\nMODEL_DIR_VIT = '../input/vitbase16/'\nMODEL_DIR_REG = '../input/cassava-regnety-weights/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \nTRAIN_PATH = '../input/cassava-leaf-disease-classification/train_images'\nTEST_PATH = '../input/cassava-leaf-disease-classification/test_images'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CFG"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug=False\n    num_workers=8\n    model_name='resnext50_32x4d' # tf_efficientnet_b4_ns, resnext50_32x4d\n    size=512\n    size_vit=384\n    batch_size=32\n    seed=2020\n    target_size=5\n    target_col='label'\n    n_fold=5\n    trn_fold=[0,1,2,3,4]\n    inference=True\n    tta=False\n    tta_vit=False\n    tta_res=False\n    tta_se=False\n    tta_ef5=False\n    num_tta=10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport sys\nsys.path.append('../input/timm-nfnet/')\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport timm\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utils"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    return accuracy_score(y_true, y_pred)\n\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n\ndef init_logger(log_file=OUTPUT_DIR+'inference.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\n#LOGGER = init_logger()\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Loading"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\ntest_ef = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['image_id'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = f'{TEST_PATH}/{file_name}'\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transforms"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    if data == 'valid':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n\ndef get_inference_transforms():\n    return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225],),\n            ToTensorV2(),\n        ])\n\ndef get_inference_transforms_vit():\n    return A.Compose([\n            A.RandomResizedCrop(CFG.size_vit, CFG.size_vit),\n#             A.Resize(CFG.size, CFG.size),\n            A.Transpose(p=0.5),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            A.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225],\n                        max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n\n\ndef get_transforms_vit(*, data):\n    if data == 'valid':\n        return A.Compose([\n            A.Resize(CFG.size_vit, CFG.size_vit),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import albumentations as A\nfrom albumentations import Compose\nfrom albumentations.pytorch import ToTensorV2\n\n\ndef get_inference_transforms_efnet4():\n    return A.Compose([\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.ShiftScaleRotate(p = 1.0),\n            A.ColorJitter(brightness=0.1, contrast=0.2, saturation=0.2, hue=0.00, always_apply=False, p=1.0),\n            A.RandomCrop(height= CFG.size, width = CFG.size,always_apply=True, p=1.0),\n            A.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225],\n                        max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomResNext(nn.Module):\n    def __init__(self, model_name='resnext50_32x4d', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)    \n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, CFG.target_size, bias=True)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomSeResNext(nn.Module):\n    def __init__(self, model_name='seresnext50_32x4d', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, CFG.target_size, bias=True)\n\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomResNextTorch(nn.Module):\n    def __init__(self, pretrained=False):\n        super().__init__()\n        self.model = models.resnext50_32x4d(pretrained = pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, CFG.target_size, bias=True)\n\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomEfficientNet(nn.Module):\n    def __init__(self, model_name=CFG.model_name, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, CFG.target_size)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ViTBase16(nn.Module):\n    def __init__(self, pretrained=False):\n\n        super(ViTBase16, self).__init__()\n        self.model = timm.create_model('vit_base_patch16_384', pretrained=False)\n        self.model.head = nn.Linear(self.model.head.in_features, CFG.target_size)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomEcaRes(nn.Module):\n    def __init__(self, model_name='ecaresnet50d', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, CFG.target_size, bias=True)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomCspRes(nn.Module):\n    def __init__(self, model_name=CFG.model_name, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.head.fc.in_features\n        self.model.head.fc = nn.Linear(n_features, CFG.target_size, bias=True)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RegNetY(nn.Module):\n    def __init__(self, model_name='regnety_080', pretrained=False):\n\n        super(RegNetY, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.head.fc.in_features\n        self.model.head.fc = nn.Linear(n_features, CFG.target_size, bias=True)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ====================================================\n# Helper functions\n# ====================================================\ndef load_state(model_path, model):\n    try:  # single GPU model_file\n        model.load_state_dict(torch.load(model_path)['model'], strict=True)\n        state_dict = torch.load(model_path)['model']\n    except:  # multi GPU model_file\n        state_dict = torch.load(model_path)['model']\n        state_dict = {k[7:] if k.startswith('module.') else k: state_dict[k] for k in state_dict.keys()}\n\n    return state_dict\n\n\ndef inference(model, states, test_loader, device):\n    model.to(device)\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        for state in states:\n            model.load_state_dict(state) \n            model.eval()\n            with torch.no_grad():\n                y_preds = model(images)\n                \n            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n        \n    probs = np.concatenate(probs)\n    return probs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ViTBase16(pretrained=False)\nstates = [load_state(MODEL_DIR_VIT+f'vit_base_patch32_384_fold{fold}_best.pth', model) for fold in CFG.trn_fold]\n\nif CFG.tta_vit == True:\n    test_dataset = TestDataset(test, transform=get_inference_transforms_vit())\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_vit = []\n    for _ in range(CFG.num_tta):\n         predictions_vit += [inference(model, states, test_loader, device)]\n    predictions_vit = np.mean(predictions_vit, axis=0)\n    \nelse:\n    test_dataset = TestDataset(test, transform=get_transforms_vit(data='valid'))\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_vit = inference(model, states, test_loader, device)\n\nprint(predictions_vit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\nmodel = CustomEfficientNet('tf_efficientnet_b4_ns', pretrained=False)\nstates = [load_state(MODEL_DIR_EFNET4+f'tf_efficientnet_b4_ns_fold{fold}_best.pth', model) for fold in CFG.trn_fold]\n\nif CFG.tta == True:\n    test_dataset = TestDataset(test, transform=get_inference_transforms_efnet4())\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_ef = []\n    \n    for _ in range(5):\n         predictions_ef += [inference(model, states, test_loader, device)]\n    predictions_ef = np.mean(predictions_ef, axis=0)\n    \nelse:\n    test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_ef = inference(model, states, test_loader, device)\n\n\n\nprint(predictions_ef)\n\n# # submission\n# test['label'] = np.argmax(predictions_ef, axis=1)\n# test[['image_id', 'label']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n# test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CustomEfficientNet('tf_efficientnet_b5_ns', pretrained=False)\nstates = [load_state(MODEL_DIR_EFNET5+f'tf_efficientnet_b5_ns_fold{fold}_best.pth', model) for fold in CFG.trn_fold]\n\nif CFG.tta_ef5 == True:\n    test_dataset = TestDataset(test, transform=get_inference_transforms())\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_ef5 = []\n    for _ in range(5):\n         predictions_ef5 += [inference(model, states, test_loader, device)]\n    predictions_ef5 = np.mean(predictions_ef5, axis=0)\n    \nelse:\n    test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_ef5 = inference(model, states, test_loader, device)\n\n\n\nprint(predictions_ef5)\n\n# submission\n# test['label'] = np.argmax(predictions_ef, axis=1)\n# test[['image_id', 'label']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n# test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CustomResNextTorch(pretrained=False)\nstates = [load_state(MODEL_DIR_RES+f'resnext50_32x4d_fold{fold}_best.pth', model) for fold in CFG.trn_fold]\n\nif CFG.tta_res == True:\n    test_dataset = TestDataset(test, transform=get_inference_transforms())\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_res = []\n    for _ in range(10):\n         predictions_res += [inference(model, states, test_loader, device)]\n    predictions_res = np.mean(predictions_res, axis=0)\n    \nelse:\n    test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_res = inference(model, states, test_loader, device)\n\nprint(predictions_res)\n\n# # # submission\n# test['label'] = np.argmax(predictions_res, axis=1)\n# test[['image_id', 'label']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n# test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CustomSeResNext('seresnext50_32x4d', pretrained=False)\nstates = [load_state(MODEL_DIR_SERES_NO+f'seresnext50_32x4d_fold{fold}_best.pth', model) for fold in CFG.trn_fold]\n\nif CFG.tta_se == True:\n    test_dataset = TestDataset(test, transform=get_inference_transforms())\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_seres = []\n    for _ in range(CFG.num_tta):\n        predictions_seres += [inference(model, states, test_loader, device)]\n        \n    predictions_seres = np.mean(predictions_seres, axis=0)\n    \nelse:\n    test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_seres = inference(model, states, test_loader, device)\n\nprint(predictions_seres)\n\n# # submission\n# test['label'] = np.argmax(predictions_seres, axis=1)\n# test[['image_id', 'label']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n# test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CustomSeResNext('seresnext50_32x4d', pretrained=False)\nstates = [load_state(MODEL_DIR_SERES_MIX+f'seresnext50_32x4d_fold{fold}_best.pth', model) for fold in CFG.trn_fold]\n\nif CFG.tta_se == True:\n    test_dataset = TestDataset(test, transform=get_inference_transforms())\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_seres_mix = []\n    for _ in range(CFG.num_tta):\n        predictions_seres_mix += [inference(model, states, test_loader, device)]\n        \n    predictions_seres_mix = np.mean(predictions_seres_mix, axis=0)\n    \nelse:\n    test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_seres_mix = inference(model, states, test_loader, device)\n\nprint(predictions_seres_mix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CustomEcaRes('ecaresnet50d', pretrained=False)\nstates = [load_state(MODEL_DIR+f'ecaresnet50d_fold{fold}_best.pth', model) for fold in CFG.trn_fold]\n\nif CFG.tta_se == True:\n    test_dataset = TestDataset(test, transform=get_inference_transforms())\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_res_removed = []\n    \n    for _ in range(5):\n         predictions_res_removed += [inference(model, states, test_loader, device)]\n    predictions_res_removed = np.mean(predictions_res_removed, axis=0)\n    \nelse:\n    test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_res_removed = inference(model, states, test_loader, device)\n\n\n\nprint(predictions_res_removed)\n\n# # submission\n# test['label'] = np.argmax(predictions_res_removed, axis=1)\n# test[['image_id', 'label']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n# test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RegNetY('regnety_080', pretrained=False)\nstates = [load_state(MODEL_DIR_REG+f'regnety_080_fold{fold}_best.pth', model) for fold in CFG.trn_fold]\n\nif CFG.tta_se == True:\n    test_dataset = TestDataset(test, transform=get_inference_transforms())\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_regnet = []\n    for _ in range(CFG.num_tta):\n        predictions_regnet += [inference(model, states, test_loader, device)]\n        \n    predictions_regnet = np.mean(predictions_regnet, axis=0)\n    \nelse:\n    test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\n    \n    predictions_regnet = inference(model, states, test_loader, device)\n\nprint(predictions_regnet)\n\n# #submission\n# test['label'] = np.argmax(predictions_regnet, axis=1)\n# test[['image_id', 'label']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\n# test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission\npredictions = 0.125*(predictions_seres + predictions_res + predictions_vit + predictions_ef5 + predictions_seres_mix + predictions_res_removed + predictions_regnet + predictions_ef)\nprint(predictions)\nprint(np.sum(predictions))\n\ntest['label'] = np.argmax(predictions, axis=1)\ntest[['image_id', 'label']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}